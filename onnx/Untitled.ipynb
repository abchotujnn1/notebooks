{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fe3b50-eb0f-4d37-8a79-a728c669dba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"XA\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XA\"\n",
      "    input: \"B\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"A\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"B\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from onnx import TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "# inputs\n",
    "\n",
    "# 'X' is the name, TensorProto.FLOAT the type, [None, None] the shape\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])\n",
    "B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])\n",
    "\n",
    "# outputs, the shape is left undefined\n",
    "\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "\n",
    "# nodes\n",
    "\n",
    "# It creates a node defined by the operator type MatMul,\n",
    "# 'X', 'A' are the inputs of the node, 'XA' the output.\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'])\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'])\n",
    "\n",
    "# from nodes to graph\n",
    "# the graph is built from the list of nodes, the list of inputs,\n",
    "# the list of outputs and a name.\n",
    "\n",
    "graph = make_graph([node1, node2],  # nodes\n",
    "                    'lr',  # a name\n",
    "                    [X, A, B],  # inputs\n",
    "                    [Y])  # outputs\n",
    "\n",
    "# onnx graph\n",
    "# there is no metadata in this case.\n",
    "\n",
    "onnx_model = make_model(graph)\n",
    "\n",
    "# Let's check the model is consistent,\n",
    "# this function is described in section\n",
    "# Checker and Shape Inference.\n",
    "check_model(onnx_model)\n",
    "\n",
    "# the work is done, let's display it...\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4007580e-abdf-4520-bf92-1c7458c5d8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** inputs **\n",
      "[name: \"X\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"A\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"B\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "** inputs **\n",
      "name='X' dtype=1 shape=(0, 0)\n",
      "name='A' dtype=1 shape=(0, 0)\n",
      "name='B' dtype=1 shape=(0, 0)\n",
      "** outputs **\n",
      "[name: \"Y\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "** outputs **\n",
      "name='Y' dtype=1 shape=(0,)\n",
      "** nodes **\n",
      "[input: \"X\"\n",
      "input: \"A\"\n",
      "output: \"XA\"\n",
      "op_type: \"MatMul\"\n",
      ", input: \"XA\"\n",
      "input: \"B\"\n",
      "output: \"Y\"\n",
      "op_type: \"Add\"\n",
      "]\n",
      "** nodes **\n",
      "name='' type='MatMul' input=['X', 'A'] output=['XA']\n",
      "name='' type='Add' input=['XA', 'B'] output=['Y']\n"
     ]
    }
   ],
   "source": [
    "from onnx import TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "def shape2tuple(shape):\n",
    "    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)\n",
    "\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])\n",
    "B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'])\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'])\n",
    "graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# the list of inputs\n",
    "print('** inputs **')\n",
    "print(onnx_model.graph.input)\n",
    "\n",
    "# in a more nicely format\n",
    "print('** inputs **')\n",
    "for obj in onnx_model.graph.input:\n",
    "    print(\"name=%r dtype=%r shape=%r\" % (\n",
    "        obj.name, obj.type.tensor_type.elem_type,\n",
    "        shape2tuple(obj.type.tensor_type.shape)))\n",
    "\n",
    "# the list of outputs\n",
    "print('** outputs **')\n",
    "print(onnx_model.graph.output)\n",
    "\n",
    "# in a more nicely format\n",
    "print('** outputs **')\n",
    "for obj in onnx_model.graph.output:\n",
    "    print(\"name=%r dtype=%r shape=%r\" % (\n",
    "        obj.name, obj.type.tensor_type.elem_type,\n",
    "        shape2tuple(obj.type.tensor_type.shape)))\n",
    "\n",
    "# the list of nodes\n",
    "print('** nodes **')\n",
    "print(onnx_model.graph.node)\n",
    "\n",
    "# in a more nicely format\n",
    "print('** nodes **')\n",
    "for node in onnx_model.graph.node:\n",
    "    print(\"name=%r type=%r input=%r output=%r\" % (\n",
    "        node.name, node.op_type, node.input, node.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b20c4da-97e5-445f-8077-363ed3a6b1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"XA\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XA\"\n",
      "    input: \"B\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"A\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"B\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from onnx import TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "def shape2tuple(shape):\n",
    "    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)\n",
    "\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])\n",
    "B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'])\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'])\n",
    "graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# The serialization\n",
    "with open(\"linear_regression.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "# display\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7d0f4a-4a09-471f-9f2a-f99375b438fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"XA\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XA\"\n",
      "    input: \"B\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"A\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"B\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from onnx import load\n",
    "\n",
    "with open(\"linear_regression.onnx\", \"rb\") as f:\n",
    "    onnx_model = load(f)\n",
    "\n",
    "# display\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f01d317-f495-4561-837c-48b9f8fa401a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'onnx.onnx_ml_pb2.TensorProto'>\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from onnx.numpy_helper import from_array\n",
    "\n",
    "numpy_tensor = numpy.array([0, 1, 4, 5, 3], dtype=numpy.float32)\n",
    "print(type(numpy_tensor))\n",
    "\n",
    "onnx_tensor = from_array(numpy_tensor)\n",
    "print(type(onnx_tensor))\n",
    "\n",
    "serialized_tensor = onnx_tensor.SerializeToString()\n",
    "print(type(serialized_tensor))\n",
    "\n",
    "with open(\"saved_tensor.pb\", \"wb\") as f:\n",
    "    f.write(serialized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b6860b-ec24-46ce-a994-b327ed1c1d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'onnx.onnx_ml_pb2.TensorProto'>\n",
      "[0. 1. 4. 5. 3.]\n"
     ]
    }
   ],
   "source": [
    "from onnx import TensorProto\n",
    "from onnx.numpy_helper import to_array\n",
    "\n",
    "with open(\"saved_tensor.pb\", \"rb\") as f:\n",
    "    serialized_tensor = f.read()\n",
    "print(type(serialized_tensor))\n",
    "\n",
    "onnx_tensor = TensorProto()\n",
    "onnx_tensor.ParseFromString(serialized_tensor)\n",
    "print(type(onnx_tensor))\n",
    "\n",
    "numpy_tensor = to_array(onnx_tensor)\n",
    "print(numpy_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c461f7d9-58f7-461a-8913-881a92eb0e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AttributeProto',\n",
      " 'FunctionProto',\n",
      " 'GraphProto',\n",
      " 'MapProto',\n",
      " 'ModelProto',\n",
      " 'NodeProto',\n",
      " 'OperatorProto',\n",
      " 'OperatorSetIdProto',\n",
      " 'OperatorSetProto',\n",
      " 'OptionalProto',\n",
      " 'SequenceProto',\n",
      " 'SparseTensorProto',\n",
      " 'StringStringEntryProto',\n",
      " 'TensorProto',\n",
      " 'TensorShapeProto',\n",
      " 'TrainingInfoProto',\n",
      " 'TypeProto',\n",
      " 'ValueInfoProto']\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import pprint\n",
    "pprint.pprint([p for p in dir(onnx)\n",
    "               if p.endswith('Proto') and p[0] != '_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b952671-8951-41de-af2a-83a040c3bdc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"AX\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"AX\"\n",
      "    input: \"C\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  initializer {\n",
      "    dims: 2\n",
      "    data_type: 1\n",
      "    name: \"A\"\n",
      "    raw_data: \"\\000\\000\\000?\\232\\231\\031\\277\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 1\n",
      "    data_type: 1\n",
      "    name: \"C\"\n",
      "    raw_data: \"\\315\\314\\314>\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from onnx import numpy_helper, TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "# initializers\n",
    "value = numpy.array([0.5, -0.6], dtype=numpy.float32)\n",
    "A = numpy_helper.from_array(value, name='A')\n",
    "\n",
    "value = numpy.array([0.4], dtype=numpy.float32)\n",
    "C = numpy_helper.from_array(value, name='C')\n",
    "\n",
    "# the part which does not change\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['AX'])\n",
    "node2 = make_node('Add', ['AX', 'C'], ['Y'])\n",
    "graph = make_graph([node1, node2], 'lr', [X], [Y], [A, C])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd78c0a-74d0-4685-9f44-20a7149d5def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [array([1.], dtype=float32)]\n",
      "\n",
      "ir_version: 8\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    output: \"rsum\"\n",
      "    op_type: \"ReduceSum\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"rsum\"\n",
      "    input: \"zero\"\n",
      "    output: \"cond\"\n",
      "    op_type: \"Greater\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"cond\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"If\"\n",
      "    attribute {\n",
      "      name: \"else_branch\"\n",
      "      g {\n",
      "        node {\n",
      "          output: \"else_out\"\n",
      "          name: \"cst2\"\n",
      "          op_type: \"Constant\"\n",
      "          attribute {\n",
      "            name: \"value\"\n",
      "            t {\n",
      "              dims: 1\n",
      "              data_type: 1\n",
      "              raw_data: \"\\000\\000\\200\\277\"\n",
      "            }\n",
      "            type: TENSOR\n",
      "          }\n",
      "        }\n",
      "        name: \"else_body\"\n",
      "        output {\n",
      "          name: \"else_out\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 5\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      type: GRAPH\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"then_branch\"\n",
      "      g {\n",
      "        node {\n",
      "          output: \"then_out\"\n",
      "          name: \"cst1\"\n",
      "          op_type: \"Constant\"\n",
      "          attribute {\n",
      "            name: \"value\"\n",
      "            t {\n",
      "              dims: 1\n",
      "              data_type: 1\n",
      "              raw_data: \"\\000\\000\\200?\"\n",
      "            }\n",
      "            type: TENSOR\n",
      "          }\n",
      "        }\n",
      "        name: \"then_body\"\n",
      "        output {\n",
      "          name: \"then_out\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      type: GRAPH\n",
      "    }\n",
      "  }\n",
      "  name: \"if\"\n",
      "  initializer {\n",
      "    dims: 1\n",
      "    data_type: 1\n",
      "    name: \"zero\"\n",
      "    raw_data: \"\\000\\000\\000\\000\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  domain: \"\"\n",
      "  version: 15\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import onnx\n",
    "from onnx.helper import (\n",
    "    make_node, make_graph, make_model, make_tensor_value_info)\n",
    "from onnx.numpy_helper import from_array\n",
    "from onnx.checker import check_model\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "# initializers\n",
    "value = numpy.array([0], dtype=numpy.float32)\n",
    "zero = from_array(value, name='zero')\n",
    "\n",
    "# Same as before, X is the input, Y is the output.\n",
    "X = make_tensor_value_info('X', onnx.TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', onnx.TensorProto.FLOAT, [None])\n",
    "\n",
    "# The node building the condition. The first one\n",
    "# sum over all axes.\n",
    "rsum = make_node('ReduceSum', ['X'], ['rsum'])\n",
    "# The second compares the result to 0.\n",
    "cond = make_node('Greater', ['rsum', 'zero'], ['cond'])\n",
    "\n",
    "# Builds the graph is the condition is True.\n",
    "# Input for then\n",
    "then_out = make_tensor_value_info(\n",
    "    'then_out', onnx.TensorProto.FLOAT, None)\n",
    "# The constant to return.\n",
    "then_cst = from_array(numpy.array([1]).astype(numpy.float32))\n",
    "\n",
    "# The only node.\n",
    "then_const_node = make_node(\n",
    "    'Constant', inputs=[],\n",
    "    outputs=['then_out'],\n",
    "    value=then_cst, name='cst1')\n",
    "\n",
    "# And the graph wrapping these elements.\n",
    "then_body = make_graph(\n",
    "    [then_const_node], 'then_body', [], [then_out])\n",
    "\n",
    "# Same process for the else branch.\n",
    "else_out = make_tensor_value_info(\n",
    "    'else_out', onnx.TensorProto.FLOAT, [5])\n",
    "else_cst = from_array(numpy.array([-1]).astype(numpy.float32))\n",
    "\n",
    "else_const_node = make_node(\n",
    "    'Constant', inputs=[],\n",
    "    outputs=['else_out'],\n",
    "    value=else_cst, name='cst2')\n",
    "\n",
    "else_body = make_graph(\n",
    "    [else_const_node], 'else_body',\n",
    "    [], [else_out])\n",
    "\n",
    "# Finally the node If taking both graphs as attributes.\n",
    "if_node = onnx.helper.make_node(\n",
    "    'If', ['cond'], ['Y'],\n",
    "    then_branch=then_body,\n",
    "    else_branch=else_body)\n",
    "\n",
    "# The final graph.\n",
    "graph = make_graph([rsum, cond, if_node], 'if', [X], [Y], [zero])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# Let's freeze the opset.\n",
    "del onnx_model.opset_import[:]\n",
    "opset = onnx_model.opset_import.add()\n",
    "opset.domain = ''\n",
    "opset.version = 15\n",
    "onnx_model.ir_version = 8\n",
    "\n",
    "# Save.\n",
    "with open(\"onnx_if_sign.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "# Let's see the output.\n",
    "sess = InferenceSession(onnx_model.SerializeToString(),\n",
    "                        providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "x = numpy.ones((3, 2), dtype=numpy.float32)\n",
    "res = sess.run(None, {'X': x})\n",
    "\n",
    "# It works.\n",
    "print(\"result\", res)\n",
    "print()\n",
    "\n",
    "# Some display.\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf9231-f536-4751-9d98-2bc0e4d5899c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
